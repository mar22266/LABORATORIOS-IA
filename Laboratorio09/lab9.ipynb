{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5dc382e",
   "metadata": {},
   "source": [
    "# Laboratorio 9\n",
    "\n",
    "## Integrantes\n",
    "\n",
    "### Sergio Orellana - 221122\n",
    "\n",
    "### Andre Marroquin - 22266\n",
    "\n",
    "### Rodrigo Mansilla - 22611\n",
    "\n",
    "# Link del repositorio\n",
    "\n",
    "https://github.com/mar22266/LABORATORIOS-IA.git\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e93d21c",
   "metadata": {},
   "source": [
    "# Tasks 1 - Teoría\n",
    "\n",
    "## 1. ¿Cuál es la diferencia entre Modelos de Markov y Hidden Markov Models?\n",
    "\n",
    "        R// Un Modelo de Markov asume que los estados del sistema son directamente observables y que la probabilidad de pasar al siguiente estado depende únicamente del estado actual, lo que es conocido como la propiedad de Markov. Por otro lado, un Hidden Markov Model esconde esos estados internos, ya que solo se pueden observar resultados o señales que provienen de un estado interno oculto que no es posible medir directamente. \n",
    "\n",
    "\n",
    "## 2. ¿Qué son los Factorial HMM (Hidden Markov Models)?\n",
    "        R// Un Factorial HMM se puede decir que es una versión más avanzada del modelo oculto de Markov que divide el estado oculto en varias partes independientes, cada una con su propia cadena de Markov. Lo que hace permitir que este logre representar situaciones donde varios procesos ocurren al mismo tiempo, como señales que se combinan entre sí. Pero, como el número de posibles combinaciones de estados aumenta muy rápido al agregar más cadenas, es oor eso que la mayormente se utilizan métodos aproximados, como los enfoques variacionales, para poder realizar los cálculos de manera eficiente.\n",
    "\n",
    "\n",
    "## 3. Especifique en sus propias palabras el algoritmo Forward-Backward para HMM\n",
    "        R// El algoritmo Forward-Backward se usa en los modelos ocultos de Markov para saber qué tan probable es que el sistema esté en cierto estado en un momento específico, tomando en cuenta todas las observaciones disponibles. Funciona en dos partes primero, la parte forward que va sumando las probabilidades desde el inicio hasta ese momento, y luego la parte backward calcula qué tan probable es que, desde ese estado, se generen las observaciones restantes. Al juntar las 2 partes, se obtiene una buena estimación de en qué estado estaba el sistema en cada instante.\n",
    "\n",
    "\n",
    "\n",
    "## 4. ¿Por qué es necesario el paso de Backward en el algoritmo Forward-Backward?\n",
    "        R// Sin backward, solo se tendría en cuenta la información acumulada hasta el instante actual, lo que limita la precisión de la estimación del estado. Al incluir la pasada backward, se incorpora también la información de las observaciones futuras, lo que permite mejorar la estimación del estado en cada momento. De esta forma, al combinar las pasadas forward y backward, se logra una probabilidad más precisa de cada estado, ya que se considera tanto la historia pasada como la futura, lo cual es bueno para obtener un resultado más completo y exacto.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094f37d0",
   "metadata": {},
   "source": [
    "# Task 2 - Algoritmo Forward Backward en HMM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4d239a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class HMM:\n",
    "    def __init__(self, states, observations, initial_prob, transition_prob, emission_prob):\n",
    "        # Inicializar parametros de HMM\n",
    "        self.states = states\n",
    "        self.observations = observations\n",
    "        self.initial_prob = initial_prob\n",
    "        self.transition_prob = transition_prob\n",
    "        self.emission_prob = emission_prob\n",
    "\n",
    "    # Genera una secuencia de observaciones  basada en el modelo\n",
    "    def generate_sequence(self, length):\n",
    "        sequence = []\n",
    "        current_state = random.choices(\n",
    "            self.states,\n",
    "            weights=[self.initial_prob[s] for s in self.states]\n",
    "        )[0]\n",
    "        sequence.append(\n",
    "            random.choices(\n",
    "                self.observations,\n",
    "                weights=[self.emission_prob[current_state][o] for o in self.observations]\n",
    "            )[0]\n",
    "        )\n",
    "        for _ in range(1, length):\n",
    "            current_state = random.choices(\n",
    "                self.states,\n",
    "                weights=[self.transition_prob[current_state][s] for s in self.states]\n",
    "            )[0]\n",
    "            sequence.append(\n",
    "                random.choices(\n",
    "                    self.observations,\n",
    "                    weights=[self.emission_prob[current_state][o] for o in self.observations]\n",
    "                )[0]\n",
    "            )\n",
    "        return sequence\n",
    "    # Calcula las probabilidades hacia adelante alfa para una secuencia de observaciones\n",
    "    def forward(self, observations):\n",
    "        T = len(observations)\n",
    "        alpha = [dict() for _ in range(T)]\n",
    "        for s in self.states:\n",
    "            alpha[0][s] = self.initial_prob[s] * self.emission_prob[s][observations[0]]\n",
    "        for t in range(1, T):\n",
    "            for s in self.states:\n",
    "                alpha[t][s] = self.emission_prob[s][observations[t]] * sum(\n",
    "                    alpha[t - 1][sp] * self.transition_prob[sp][s]\n",
    "                    for sp in self.states\n",
    "                )\n",
    "        return alpha\n",
    "    # Calcula las probabilidades hacia atrás beta para una secuencia de observaciones\n",
    "    def backward(self, observations):\n",
    "        T = len(observations)\n",
    "        beta = [dict() for _ in range(T)]\n",
    "        for s in self.states:\n",
    "            beta[T - 1][s] = 1.0\n",
    "        for t in range(T - 2, -1, -1):\n",
    "            for s in self.states:\n",
    "                beta[t][s] = sum(\n",
    "                    self.transition_prob[s][sp] *\n",
    "                    self.emission_prob[sp][observations[t + 1]] *\n",
    "                    beta[t + 1][sp]\n",
    "                    for sp in self.states\n",
    "                )\n",
    "        return beta\n",
    "    # Combina alpha y beta para calcular probabilidades de estado gamma en cada paso de tiempo\n",
    "    def compute_state_probabilities(self, observations):\n",
    "        alpha = self.forward(observations)\n",
    "        beta = self.backward(observations)\n",
    "        T = len(observations)\n",
    "        gamma = [dict() for _ in range(T)]\n",
    "        for t in range(T):\n",
    "            denom = sum(alpha[t][s] * beta[t][s] for s in self.states)\n",
    "            for s in self.states:\n",
    "                gamma[t][s] = (alpha[t][s] * beta[t][s]) / denom if denom != 0 else 0\n",
    "        return gamma\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149b6948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Secuencia Generada: ['Sunny', 'Rainy', 'Sunny', 'Rainy', 'Rainy']\n",
      "\n",
      "Probabilidades Forward:\n",
      " t=0: {'Sunny': 0.4, 'Rainy': 0.15}\n",
      " t=1: {'Sunny': 0.30400000000000005, 'Rainy': 0.051000000000000004}\n",
      " t=2: {'Sunny': 0.05272000000000002, 'Rainy': 0.06398000000000001}\n",
      "\n",
      "Probabilidades Backward:\n",
      " t=0: {'Sunny': 0.22200000000000006, 'Rainy': 0.18600000000000003}\n",
      " t=1: {'Sunny': 0.30000000000000004, 'Rainy': 0.5}\n",
      " t=2: {'Sunny': 1.0, 'Rainy': 1.0}\n",
      "\n",
      "Probabilidades de Estado:\n",
      " t=0: {'Sunny': 0.7609254498714653, 'Rainy': 0.23907455012853465}\n",
      " t=1: {'Sunny': 0.7814910025706941, 'Rainy': 0.21850899742930588}\n",
      " t=2: {'Sunny': 0.45175664095972584, 'Rainy': 0.5482433590402742}\n"
     ]
    }
   ],
   "source": [
    "# Definir parametros del HMM\n",
    "states = ['Sunny', 'Rainy']\n",
    "observations = ['Sunny', 'Rainy']\n",
    "initial_prob = {'Sunny': 0.5, 'Rainy': 0.5}\n",
    "transition_prob = {\n",
    "    'Sunny': {'Sunny': 0.8, 'Rainy': 0.2},\n",
    "    'Rainy': {'Sunny': 0.4, 'Rainy': 0.6}\n",
    "}\n",
    "emission_prob = {\n",
    "    'Sunny': {'Sunny': 0.8, 'Rainy': 0.2},\n",
    "    'Rainy': {'Sunny': 0.3, 'Rainy': 0.7}\n",
    "}\n",
    "\n",
    "# Crear instancia de HMM\n",
    "hmm = HMM(states, observations, initial_prob, transition_prob, emission_prob)\n",
    "\n",
    "# Generar secuencia de observaciones \n",
    "seq = hmm.generate_sequence(5)\n",
    "print(\"Secuencia Generada:\", seq)\n",
    "\n",
    "# Secuencia de observaciones para algoritmos\n",
    "obs_seq = ['Sunny', 'Sunny', 'Rainy']\n",
    "\n",
    "# Probabilidades Forward\n",
    "fwd = hmm.forward(obs_seq)\n",
    "print(\"\\nProbabilidades Forward:\")\n",
    "for t, probs in enumerate(fwd):\n",
    "    print(f\" t={t}: {probs}\")\n",
    "\n",
    "# Probabilidades Backward\n",
    "bwd = hmm.backward(obs_seq)\n",
    "print(\"\\nProbabilidades Backward:\")\n",
    "for t, probs in enumerate(bwd):\n",
    "    print(f\" t={t}: {probs}\")\n",
    "\n",
    "# Probabilidades de Estado \n",
    "gamma = hmm.compute_state_probabilities(obs_seq)\n",
    "print(\"\\nProbabilidades de Estado:\")\n",
    "for t, probs in enumerate(gamma):\n",
    "    print(f\" t={t}: {probs}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e22aa8",
   "metadata": {},
   "source": [
    "Refrencias:\n",
    "\n",
    "- GeeksforGeeks. (2024b, junio 25). What Is the Difference Between Markov Chains and Hidden Markov Models? GeeksforGeeks. https://www.geeksforgeeks.org/what-is-the-difference-between-markov-chains-and-hidden-markov-models/\n",
    "\n",
    "- Genç, E. (2024, 29 febrero). Factorial Hidden Markov Model for Time Series Analysis in Python. Medium. https://medium.com/@erdal.genc09/factorial-hidden-markov-model-for-time-series-analysis-in-python-4c6d6f33860b\n",
    "\n",
    "- Forward and Backward Algorithm in Hidden Markov Model. (2019, 17 febrero). A Developer Diary. https://adeveloperdiary.com/data-science/machine-learning/forward-and-backward-algorithm-in-hidden-markov-model/\n",
    "\n",
    "- Forward-backward algorithm for HMM. (s. f.). Cross Validated. https://stats.stackexchange.com/questions/275413/forward-backward-algorithm-for-hmm\n",
    "\n",
    "- Pramod, O. (2023, 30 diciembre). Hidden Markov Models: The Secret Sauce in Natural Language Processing. Medium. https://medium.com/@ompramod9921/hidden-markov-models-the-secret-sauce-in-natural-language-processing-5273503a33f6\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
