{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Laboratorio 2\n",
    "\n",
    "### Andre Marroquin Tarot- 22266\n",
    "\n",
    "### Sergio Orellana- 221122\n",
    "\n",
    "### Rodrigo Mansilla 22611\n",
    "\n",
    "LINK GIT: https://github.com/mar22266/LABORATORIOS-IA.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1 - Preguntas Teóricas\n",
    "\n",
    "1. ¿Por qué el modelo de Naive Bayes se le considera “naive”?\n",
    "\n",
    "    R//\n",
    "\n",
    "\n",
    "2. Explique la formulación matemática que se busca optimizar en Support Vector Machine, además responda\n",
    "¿cómo funciona el truco del Kernel para este modelo? (Lo que se espera de esta pregunta es que puedan\n",
    "explicar en sus propias palabras la fórmula a la que llegamos que debemos optimizar de SVM en clase)\n",
    "\n",
    "    R//\n",
    "\n",
    "\n",
    "3. Investigue sobre Random Forest y responda\n",
    "\n",
    "    a. ¿Qué tipo de ensemble learning es este modelo?\n",
    "\n",
    "        R//\n",
    "\n",
    "    b. ¿Cuál es la idea general detrás de Random Forest?\n",
    "\n",
    "        R//\n",
    "\n",
    "    c. ¿Por qué se busca baja correlación entre los árboles de Random Forest?\n",
    "\n",
    "        R//"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2 y 2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar Librerías Necesarias\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer y Limpiar el Dataset\n",
    "\n",
    "def cargar_y_limpiar_dataset(ruta):\n",
    "    mensajes = []\n",
    "    etiquetas = []\n",
    "\n",
    "    with open(ruta, 'r', encoding='utf-8') as archivo:\n",
    "        for linea in archivo:\n",
    "            linea = linea.strip()  # Quitar espacios en blanco iniciales y finales\n",
    "            if not linea:\n",
    "                continue\n",
    "            etiqueta, mensaje = linea.split('\\t', 1)  # Dividir etiqueta y mensaje\n",
    "            etiqueta = etiqueta.lower()  # Normalizar etiquetas a minúsculas\n",
    "            mensaje = re.sub(r'[^a-zA-Z0-9\\s]', '', mensaje).lower()  # Quitar caracteres especiales\n",
    "            mensajes.append(mensaje)\n",
    "            etiquetas.append(1 if etiqueta == 'spam' else 0)  # 1 para spam, 0 para ham\n",
    "\n",
    "    return mensajes, etiquetas\n",
    "\n",
    "# Cargar y limpiar el dataset\n",
    "ruta_dataset = 'entrenamiento.txt'\n",
    "mensajes, etiquetas = cargar_y_limpiar_dataset(ruta_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Dividir en Conjuntos de Entrenamiento, Prueba y Validación\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(mensajes, etiquetas, test_size=0.2, random_state=42)  # 80% entrenamiento\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)  # 10% validación, 10% prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementar Naive Bayes con Laplace Smoothing\n",
    "\n",
    "def calcular_probabilidades(X, y):\n",
    "    # Calcular probabilidades de Naive Bayes con Laplace Smoothing\n",
    "    vocabulario = set(word for mensaje in X for word in mensaje.split())\n",
    "    vocab_size = len(vocabulario)\n",
    "\n",
    "    # Inicializar conteos y probabilidades\n",
    "    conteo_palabras = {clase: {} for clase in [0, 1]}\n",
    "    total_palabras = {clase: 0 for clase in [0, 1]}\n",
    "    prob_clase = {}\n",
    "\n",
    "    for clase in [0, 1]:\n",
    "        mensajes_clase = [X[i] for i in range(len(X)) if y[i] == clase]\n",
    "        total_mensajes = len(mensajes_clase)\n",
    "        prob_clase[clase] = total_mensajes / len(y)\n",
    "\n",
    "        for mensaje in mensajes_clase:\n",
    "            for palabra in mensaje.split():\n",
    "                if palabra not in conteo_palabras[clase]:\n",
    "                    conteo_palabras[clase][palabra] = 0\n",
    "                conteo_palabras[clase][palabra] += 1\n",
    "                total_palabras[clase] += 1\n",
    "\n",
    "    return vocabulario, vocab_size, conteo_palabras, total_palabras, prob_clase\n",
    "\n",
    "# Calcular probabilidades para el modelo\n",
    "vocabulario, vocab_size, conteo_palabras, total_palabras, prob_clase = calcular_probabilidades(X_train, y_train)\n",
    "\n",
    "def predecir(X, vocabulario, vocab_size, conteo_palabras, total_palabras, prob_clase):\n",
    "    # Predecir etiquetas para nuevos mensajes\n",
    "    predicciones = []\n",
    "\n",
    "    for mensaje in X:\n",
    "        probabilidades = {}\n",
    "        for clase in [0, 1]:\n",
    "            probabilidad = np.log(prob_clase[clase])\n",
    "            for palabra in mensaje.split():\n",
    "                conteo = conteo_palabras[clase].get(palabra, 0)\n",
    "                probabilidad += np.log((conteo + 1) / (total_palabras[clase] + vocab_size))\n",
    "            probabilidades[clase] = probabilidad\n",
    "\n",
    "        predicciones.append(max(probabilidades, key=probabilidades.get))\n",
    "\n",
    "    return predicciones\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9784560143626571\n",
      "Confusion Matrix:\n",
      " [[472  10]\n",
      " [  2  73]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99       482\n",
      "           1       0.88      0.97      0.92        75\n",
      "\n",
      "    accuracy                           0.98       557\n",
      "   macro avg       0.94      0.98      0.96       557\n",
      "weighted avg       0.98      0.98      0.98       557\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluar el Modelo\n",
    "y_pred = predecir(X_test, vocabulario, vocab_size, conteo_palabras, total_palabras, prob_clase)\n",
    "\n",
    "# Métricas de desempeño\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "reporte = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "print(\"Classification Report:\\n\", reporte)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construcción del Modelo\n",
    "\n",
    "def calcular_probabilidades(X, y):\n",
    "    # Calcular probabilidades de Naive Bayes con Laplace Smoothing\n",
    "    vocabulario = set(word for mensaje in X for word in mensaje.split())\n",
    "    vocab_size = len(vocabulario)\n",
    "\n",
    "    # Inicializar conteos y probabilidades\n",
    "    conteo_palabras = {clase: {} for clase in [0, 1]}\n",
    "    total_palabras = {clase: 0 for clase in [0, 1]}\n",
    "    prob_clase = {}\n",
    "\n",
    "    for clase in [0, 1]:\n",
    "        mensajes_clase = [X[i] for i in range(len(X)) if y[i] == clase]\n",
    "        total_mensajes = len(mensajes_clase)\n",
    "        prob_clase[clase] = total_mensajes / len(y)\n",
    "\n",
    "        for mensaje in mensajes_clase:\n",
    "            for palabra in mensaje.split():\n",
    "                if palabra not in conteo_palabras[clase]:\n",
    "                    conteo_palabras[clase][palabra] = 0\n",
    "                conteo_palabras[clase][palabra] += 1\n",
    "                total_palabras[clase] += 1\n",
    "\n",
    "    return vocabulario, vocab_size, conteo_palabras, total_palabras, prob_clase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular probabilidades usando solo el conjunto de entrenamiento\n",
    "vocabulario, vocab_size, conteo_palabras, total_palabras, prob_clase = calcular_probabilidades(X_train, y_train)\n",
    "\n",
    "def predecir(X, vocabulario, vocab_size, conteo_palabras, total_palabras, prob_clase):\n",
    "    \"\"\"Predecir etiquetas para nuevos mensajes.\"\"\"\n",
    "    predicciones = []\n",
    "\n",
    "    for mensaje in X:\n",
    "        probabilidades = {}\n",
    "        for clase in [0, 1]:\n",
    "            probabilidad = np.log(prob_clase[clase])\n",
    "            for palabra in mensaje.split():\n",
    "                conteo = conteo_palabras[clase].get(palabra, 0)\n",
    "                probabilidad += np.log((conteo + 1) / (total_palabras[clase] + vocab_size))\n",
    "            probabilidades[clase] = probabilidad\n",
    "\n",
    "        predicciones.append(max(probabilidades, key=probabilidades.get))\n",
    "\n",
    "    return predicciones\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy en el conjunto de entrenamiento: 0.9912398921832885\n",
      "Matriz de confusión en el conjunto de entrenamiento:\n",
      " [[3854   14]\n",
      " [  25  559]]\n",
      "Accuracy en el conjunto de prueba: 0.9784560143626571\n",
      "Matriz de confusión en el conjunto de prueba:\n",
      " [[472  10]\n",
      " [  2  73]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluación del Modelo\n",
    "# Predecir sobre el conjunto de entrenamiento\n",
    "y_train_pred = predecir(X_train, vocabulario, vocab_size, conteo_palabras, total_palabras, prob_clase)\n",
    "\n",
    "# Predecir sobre el conjunto de prueba\n",
    "y_test_pred = predecir(X_test, vocabulario, vocab_size, conteo_palabras, total_palabras, prob_clase)\n",
    "\n",
    "# Calcular métricas de desempeño\n",
    "accuracy_train = accuracy_score(y_train, y_train_pred)\n",
    "accuracy_test = accuracy_score(y_test, y_test_pred)\n",
    "conf_matrix_train = confusion_matrix(y_train, y_train_pred)\n",
    "conf_matrix_test = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "print(\"Accuracy en el conjunto de entrenamiento:\", accuracy_train)\n",
    "print(\"Matriz de confusión en el conjunto de entrenamiento:\\n\", conf_matrix_train)\n",
    "print(\"Accuracy en el conjunto de prueba:\", accuracy_test)\n",
    "print(\"Matriz de confusión en el conjunto de prueba:\\n\", conf_matrix_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Justificación de la métrica utilizada\n",
    "## Accuracy es una métrica adecuada dado que el dataset tiene una distribución balanceada entre clases ham y spam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mensaje ingresado: hola me llamo andre\n",
      "Probabilidades: {0: -37.190714021335005, 1: -38.7920862010779}\n",
      "Clasificación: ham\n",
      "Mensaje ingresado: ATENCION\n",
      "Probabilidades: {0: -11.178147188857753, 1: -12.045386563945964}\n",
      "Clasificación: ham\n",
      "Mensaje ingresado: ingresa tu numero ya\n",
      "Probabilidades: {0: -40.41954017705637, 1: -41.39477588652228}\n",
      "Clasificación: ham\n",
      "Mensaje ingresado: promocion de dos por 1\n",
      "Probabilidades: {0: -49.009304407253325, 1: -48.76989739128578}\n",
      "Clasificación: spam\n",
      "Mensaje ingresado: \n",
      "Probabilidades: {0: -0.14061585582225045, 1: -2.031207729567208}\n",
      "Clasificación: ham\n"
     ]
    }
   ],
   "source": [
    "# Clasificación de Mensajes Futuros\n",
    "def clasificar_mensaje(mensaje, vocabulario, vocab_size, conteo_palabras, total_palabras, prob_clase):\n",
    "    \"\"\"Clasificar un mensaje individual como spam o ham y devolver las probabilidades.\"\"\"\n",
    "    mensaje_original = mensaje  # Guardar mensaje original\n",
    "    mensaje = re.sub(r'[^a-zA-Z0-9\\s]', '', mensaje).lower()  # Limpiar mensaje\n",
    "    probabilidades = {}\n",
    "    for clase in [0, 1]:\n",
    "        probabilidad = np.log(prob_clase[clase])\n",
    "        for palabra in mensaje.split():\n",
    "            conteo = conteo_palabras[clase].get(palabra, 0)\n",
    "            probabilidad += np.log((conteo + 1) / (total_palabras[clase] + vocab_size))\n",
    "        probabilidades[clase] = probabilidad\n",
    "\n",
    "    clase_predicha = max(probabilidades, key=probabilidades.get)\n",
    "    return mensaje_original, probabilidades, \"spam\" if clase_predicha == 1 else \"ham\"\n",
    "\n",
    "# Interfaz para clasificar mensajes nuevos\n",
    "while True:\n",
    "    mensaje = input(\"Ingrese un mensaje para clasificar (o 'salir' para terminar): \")\n",
    "    if mensaje.lower() == 'salir':\n",
    "        break\n",
    "    mensaje_original, probabilidades, clasificacion = clasificar_mensaje(mensaje, vocabulario, vocab_size, conteo_palabras, total_palabras, prob_clase)\n",
    "    print(f\"Mensaje ingresado: {mensaje_original}\")\n",
    "    # La probabilidad logarítmica de que el mensaje pertenezca a la clase ham(0) o spam(1)\n",
    "    print(f\"Probabilidades: {probabilidades}\")\n",
    "    print(f\"Clasificación: {clasificacion}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resultados utilizando sklearn.naive_bayes.MultinomialNB\n",
      "Accuracy en el conjunto de entrenamiento: 0.9914645103324349\n",
      "Accuracy en el conjunto de prueba: 0.9838420107719928\n"
     ]
    }
   ],
   "source": [
    "# Comparación con Librerías\n",
    "# Entrenamiento con sklearn.naive_bayes.MultinomialNB\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_vect = vectorizer.fit_transform(X_train)\n",
    "X_test_vect = vectorizer.transform(X_test)\n",
    "\n",
    "modelo_sklearn = MultinomialNB()\n",
    "modelo_sklearn.fit(X_train_vect, y_train)\n",
    "\n",
    "# Predicción sobre el conjunto de entrenamiento y prueba\n",
    "y_train_pred_sklearn = modelo_sklearn.predict(X_train_vect)\n",
    "y_test_pred_sklearn = modelo_sklearn.predict(X_test_vect)\n",
    "\n",
    "# Métricas de desempeño para sklearn\n",
    "accuracy_train_sklearn = accuracy_score(y_train, y_train_pred_sklearn)\n",
    "accuracy_test_sklearn = accuracy_score(y_test, y_test_pred_sklearn)\n",
    "\n",
    "print(\"\\nResultados utilizando sklearn.naive_bayes.MultinomialNB\")\n",
    "print(\"Accuracy en el conjunto de entrenamiento:\", accuracy_train_sklearn)\n",
    "print(\"Accuracy en el conjunto de prueba:\", accuracy_test_sklearn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## ¿Cuál implementación lo hizo mejor?\n",
    "\n",
    "La implementación de la librería **sklearn** fue superior en términos de desempeño comparado con la implementación manual:\n",
    "\n",
    "- **Entrenamiento:**\n",
    "  - **sklearn:** Obtuvó una precisión de 0.9915\n",
    "  - **Manual:** Obtuvo una precisión de 0.9912\n",
    "\n",
    "- **Prueba:**\n",
    "  - **sklearn:** Alcanzó 0.9838\n",
    "  - **Manual:** Obtuvo 0.9785\n",
    "\n",
    "\n",
    "\n",
    "## ¿Por qué cree que se debe esta diferencia?\n",
    "\n",
    "La diferencia en el desempeño entre sklearn y la implementación manual se puede deber a algunos factores:\n",
    "\n",
    "   - La implementación de sklearn utiliza algoritmos optimizados que incluyen el manejo eficiente de datos y operaciones matemáticas en bajo nivel.\n",
    "\n",
    "   - MultinomialNB maneja de forma nativa problemas como el underflow numérico y aplica ajustes internos que mejoran la estabilidad de los cálculos.\n",
    "\n",
    "   - La herramienta CountVectorizer y el modelo de sklearn aseguran un tratamiento consistente del texto, lo que reduce posibles errores en la preparación manual.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
