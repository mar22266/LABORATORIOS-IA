{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hoja de Trabajo 2\n",
    "\n",
    "## Integrantes\n",
    "\n",
    "### Sergio Orellana - 221122\n",
    "\n",
    "### Andre Marroquin - 22266\n",
    "\n",
    "### Rodrigo Mansilla - 22611\n",
    "\n",
    "# Link del repositorio\n",
    "\n",
    "https://github.com/mar22266/LABORATORIOS-IA.git\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1 - Preguntas Teóricas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Responda a cada de las siguientes preguntas de forma clara y lo más completamente posible.\n",
    "1. Defina el proceso de decisión de Markov (MDP) y explique sus componentes.\n",
    "\n",
    "        R//\n",
    "\n",
    "\n",
    "2. Describa cual es la diferencia entre política, evaluación de políticas, mejora de políticas e iteración de políticas en el contexto de los PDM.\n",
    "\n",
    "        R//\n",
    "\n",
    "\n",
    "\n",
    "3. Explique el concepto de factor de descuento (gamma) en los MDP. ¿Cómo influye en la toma de decisiones?\n",
    "\n",
    "        R//\n",
    "\n",
    "\n",
    "4. Analice la diferencia entre los algoritmos de iteración de valores y de iteración de políticas para resolver MDP.\n",
    "\n",
    "        R//\n",
    "\n",
    "\n",
    "5. ¿Cuáles son algunos desafíos o limitaciones comunes asociados con la resolución de MDP a gran escala?\n",
    "Discuta los enfoques potenciales para abordar estos desafíos.\n",
    "\n",
    "        R//"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2 - Preguntas Analíticas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Responda a cada de las siguientes preguntas de forma clara y lo más completamente posible.\n",
    "\n",
    "1. Analice críticamente los supuestos subyacentes a la propiedad de Markov en los Procesos de Decisión de\n",
    "Markov (MDP). Analice escenarios en los que estos supuestos puedan no ser válidos y sus implicaciones\n",
    "para la toma de decisiones.\n",
    "\n",
    "        R//\n",
    "\n",
    "\n",
    "2. Explore los desafíos de modelar la incertidumbre en los procesos de decisión de Markov (MDP) y analice\n",
    "estrategias para una toma de decisiones sólida en entornos inciertos.\n",
    "\n",
    "        R//"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3 - Preguntas Prácticas"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
